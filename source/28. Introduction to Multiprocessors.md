# 28. Introduction to Multiprocessors
```text
第28章多处理器介绍
AP SHANTHI博士

 

本模块的目标是讨论不同类型的并行处理器以及设计并行处理器时要考虑的主要问题。

 

我们知道应用程序表现出不同类型的并行性，并且体系结构试图利用它们。在我们之前的模块中，我们研究了利用 ILP 的不同技术。我们还研究了如何使用细粒度和粗粒度多线程来利用线程级并行性。ILP 和 TLP 都可以与 SMT 结合使用。然而，当采用 SMT 时，由于共享缓存、分支预测器、寄存器等，单线程性能可能会下降。可以通过尝试优先处理或优先选择一两个线程来减轻这种影响。有几个与 SMT 相关的设计挑战，如下所示：

 

• 多少线程？

 

– 许多找到足够的并行性

 

– 但是，混合多个线程会影响单个线程的执行

 

• 处理器前端（指令获取）

 

– 尽可能在单个线程中获取（以最大化线程性能）

 

– 但是，这限制了可从其他线程调度的指令数量

 

• 需要更大的寄存器文件

 

– 为了存储多个上下文

 

• 最小化时钟周期时间

 

– 不影响时钟周期，特别是在指令发布等关键步骤中，需要考虑更多候选指令，以及在指令完成中，选择要提交的指令可能具有挑战性

 

• 缓存冲突

 

– 确保多线程同时执行产生的缓存和TLB冲突不会造成显着的性能下降

 

• 归根结底，它只是一个物理处理器

 

– 尽管 SMT 可以实现更好的线程化（例如高达 30%），但操作系统和应用程序将每个并发线程视为一个单独的“虚拟处理器”，芯片只有每个资源的一个副本

 

• 难以使单核时钟频率更高

 

• 深度流水线电路：

 

– 热量问题

 

– 时钟问题

 

– 效率（失速）问题

 

• 将今天的每时钟 3-6 条指令（例如 6 至 12 条指令）的问题率加倍是极其困难的

 

– 每个周期发出 3 或 4 次数据存储器访问，

 

– 每个周期重命名和访问 20 多个寄存器，以及

 

– 每个周期取 12 到 24 条指令

 

已经表明，在具有许多资源的处理器中使用 8 个线程，SMT 可将吞吐量提高大约 2-4。Alpha 21464、IBM Power5 和 Intel Pentium 4 是 SMT 的示例。

 

与 SMT 相关的挑战和因利用 ILP 的收益递减而导致的单处理器性能下降，再加上对功耗的日益关注，正在引领计算机体系结构的新时代——多处理器发挥主要作用的时代。其他因素也加强了这一点，例如：

 

• 对服务器和服务器性能的兴趣日益浓厚

 

• 应用程序变得越来越数据密集

 

• 对许多应用程序而言，提高桌面性能并不重要的见解

 

• 更好地理解如何有效地使用多处理器

 

• 通过复制而不是独特设计来利用设计投资的优势——所有多处理器设计都提供了这种利用

 

Thus, Multi-core architectures have come to dominate the market. Here, there are several cores, where each is smaller and not as powerful (but also easier to design and manufacture). They are however, great with thread-level parallelism. On the other hand, SMT processors can have one large and fast superscalar core, which has great performance on a single thread and mostly still only exploits instruction-level parallelism.

 

The traditional definition of a parallel computer goes like this: “A parallel computer is a collection of processing elements that cooperate and communicate to solve large problems fast” (Almasi and Gottlieb, Highly Parallel Computing ,1989). Whenever we talk of parallel computers, the popular questions to be answered are:

 

– How large a collection?

 

– How powerful are processing elements?

 

– 他们如何合作和沟通？

 

– 数据是如何传输的？

    – 什么类型的互连？

 

– 程序员的硬件和软件原语是什么？

 

– 什么是编程模型？

 

– 它如何转化为性能？

 

我们将尝试在本模块和一些后续模块中回答这些问题中的大部分。

 

计算机分类：首先，我们来看看 Michael Flynn 是如何根据指令流和数据流的数量对计算机系统进行分类的。据他介绍，计算机可以归为以下四类之一：

 

1. 单指令流、单数据流（SISD）——这一类是单处理器。

 

2. 单指令流、多数据流（SIMD）——同一指令由使用不同数据流的多个处理器执行。SIMD 计算机通过对多个数据项并行应用相同的操作来利用数据级并行性。每个处理器都有自己的数据存储器（因此有多个数据），但只有一个指令存储器和控制处理器，用于获取和分派指令。对于显示重要数据级并行性的应用程序，SIMD 方法可能非常有效。处理器 ISA 中可用的多媒体扩展是 SIMD 并行的一种形式。矢量体系结构是最大的一类 SIMD 体系结构。SIMD 风格的架构示例包括 Illiac-IV 和 CM-2。它们具有以下特点：

 

一世。简单的编程模型

ii. 低开销

三、灵活性

四、所有定制集成电路

 

我们将在后面的模块中讨论利用数据级并行性的所有不同方法。

 

3. 多指令流、单数据流 (MISD)——迄今为止还没有构建这种类型的商业多处理器。

 

4. 多指令流、多数据流 (MIMD)——每个处理器获取自己的指令并对自己的数据进行操作。MIMD 计算机利用线程级并行性，因为多个线程并行运行。一般来说，线程级并行比数据级并行更灵活，因此更普遍适用。示例包括 Sun Enterprise 5000、Cray T3D 和 SGI Origin。他们是

 

一世。灵活的

    ii. 使用现成的微处理器，因此具有成本/性能优势

 

iii. Most common parallel computing platform Multicore processors fall under this category.

 

We shall discuss the MIMD style of architectures in this module.

 

Classes of MIMD architectures: There are basically two types of MIMD architectures, depending on the number of processors involved, which in turn dictates a memory organization and interconnect strategy. We classify multiprocessors based on their memory organization as centralized shared-memory architectures and distributed shared memory architectures. The centralized shared memory architectures normally have a few processors sharing a single centralized memory through a bus based interconnect or a switch. With large caches, a single memory, possibly with multiple banks, can satisfy the memory demands of a small number of processors. However, scalability is limited as sharing a centralized memory becomes very cumbersome as the number of processors increases. Because there is a single main memory, it has a symmetric relationship to all processors and a uniform access time from any processor, and these multiprocessors are most often called symmetric (shared-memory) multiprocessors (SMPs), and this style of architecture is also called uniform memory access (UMA)，这是因为所有处理器都具有统一的内存延迟，即使内存被组织成多个银行。图 32.1 显示了这种多处理器的组织结构。

 


 

第二类由具有物理分布式内存的多处理器组成。图 32.2 显示了这些多处理器的外观。为了处理可扩展性问题，内存必须分布在处理器之间而不是集中。每个处理器都有自己的本地内存，也可以访问其他处理器的内存。处理器数量的增加也提高了对高带宽互连的需求。


 

在节点之间分配内存有两个主要好处。首先，如果大多数访问是对节点中的本地内存，它是一种扩展内存带宽的经济有效的方法。其次，它减少了访问本地内存的延迟。这两个优点使分布式内存具有吸引力。分布式内存架构的缺点是处理器之间的数据通信变得更加复杂，并且需要在软件中付出更多努力才能利用分布式内存提供的增加的内存带宽。两种架构风格的比较如下：

集中式共享内存架构
统一内存访问时间——UMA 处理器
对称处理器 – 对称共享内存多处理器 (SMP)
Interconnection is traditionally through a bus – scalability problem
Simpler software model
Decentralized or distributed memory architectures
Non-uniform memory access time – NUMA processors
Get more memory bandwidth, lower memory latency
Drawback: Longer communication latency
Drawback: Software model more complex
 

Models for Communication: As we have seen, in order to handle the scalability problem, we need to distribute the memory among multiple processors. The use of distributed memory leads to two different paradigms for inter-processor communication, transferring data from one processor to another – shared memory model and message passing model. The comparison between the two models is given below.

 

1. Shared Memory with “Non Uniform Memory Access” time (NUMA)

There is logically one address space and the communication happens through the shared address space, as in the case of a symmetric shared memory architecture. One processor writes the data in a shared location and the other processor reads it from the shared location.
 

2. Message passing “multicomputer” with separate address space per processor

 

• Each processor has its own address space. It is still NUMA style of architecture. In this case, we can invoke software with Remote Procedure Calls (RPC).

 

• This is normally done through libraries such as MPI (Message Passing Interface).

 

• Also called “Synchronous communication” since communication causes synchronization between 2 processes.

 

共享内存通信模型的优点：基于以上讨论，可以展示两种通信模型的优点。共享内存模型具有以下优点：

 

1、本机型兼容SMP硬件。

 

2. 当通信模式复杂或在执行过程中动态变化时，易于编程。

 

3. 该模型提供了使用熟悉的 SMP 模型开发应用程序的能力，只关注性能关键访问。

 

4. 由于隐式通信和内存映射在硬件中实现保护，而不是通过 I/O 系统，因此小项目的通信开销更低，带宽利用率更高。

 

5. 使用硬件控制的缓存通过缓存所有共享和私有数据来减少远程通信。

 

消息传递通信模型的优点：所述的消息传递通信模型具有以下优点：

 

1.硬件可以更简单。（尤其是对 NUMA）

 

2. 沟通是明确的，这意味着更容易理解；在共享内存中，很难知道什么时候通信，什么时候不通信，以及通信成本有多大。

 

3. 显式通信侧重于计算，有时会导致程序。关注多处理器并行改进结构的代价高昂的方面

 

4. 同步自然与发送消息相关联，减少不正确同步引入错误的可能性

 

5.更容易使用发送者发起的通信，这可能在性能上有一些优势

 

数据并行模型：另一种编程模型，我们将在后面详细讨论其架构特征是数据并行模型。其显着特点如下：

 

1. 在这里，可以对大型常规数据结构（例如数组）的每个元素并行执行操作。

 

2. 有一个控制处理器向许多处理元素广播。

 

3. 支持每个 PE 的条件标志，以便可以跳过某些操作。

 

4.数据分布在每个内存中。

 

5. 存在数据并行编程语言，可将数据布局到处理元素。

 

6. 这种 SIMD 编程模型导致了单程序多数据 (SPMD) 模型，其中所有处理器都执行相同的程序。

 

编程模型摘要：编程模型是程序员在编码应用程序中使用的机器的概念化。它基本上定义了部件如何协作和协调它们的活动。它还指定了通信和同步操作。我们讨论过的各种编程模型可以总结为：

 

• 多道程序设计

 

– 在程序级别没有通信或同步

 

• 共享地址空间

 

– 像公告板

 

• 消息传递

 

– 像信件或电话，明确的点对点

 

• 数据并行：

 

– 更有条理的全球数据行动

 

– 通过共享地址空间或消息传递实现

 

通信机制的性能指标：在查看了不同风格的多处理器架构之后，我们现在将关注用于评估此类系统的性能指标。多处理器系统的性能是根据通信带宽、通信延迟和用于隐藏通信延迟的技术来评估的。

 

1. 通信带宽

    – 我们通常需要高带宽的通信。

 

– 这受处理器、内存和互连带宽的限制。

 

2. 通信延迟

 

– 这会影响性能，因为处理器可能必须等待数据到达。

 

– 它会影响编程的简易性，因为需要更多的思考来重叠通信和计算。

 

– 通信开销是许多机器的问题。

 

3. 通信延迟隐藏

 

– 有哪些机制可以帮助隐藏延迟？

 

– 这会增加编程系统的负担。示例包括将消息发送与计算重叠、预取数据、切换到其他任务等。

 

因此，无论哪种架构风格提供高通信带宽、低通信延迟和支持隐藏通信延迟的技术都是首选。

 

并行处理的挑战：当我们查看多处理器系统时，我们可能会运行各种任务，从完全不需要通信的独立任务到可能需要在它们之间进行大量通信的任务。因此，有两个重要的障碍使并行处理具有挑战性。它们是程序中可用的并行量和通信开销。这两者都可以用阿姆达尔定律来解释，这些障碍的难易程度由应用程序和底层架构决定。

 

第一个障碍与程序中普遍可用的有限并行性有关。可用并行性的限制使得很难在任何并行处理器中实现良好的加速。下面的例子说明了并行性在程序中的重要性。假设我们希望使用 100 个处理器实现 80 的整体加速。在这种情况下，我们可以计算原始计算中可以顺序执行的部分。将此应用于阿姆达尔定律，并假设程序仅在两种模式下运行——并行所有处理器完全使用，这是增强模式，或串行只使用一个处理器，我们发现程序的只有 0.25% 应该是顺序的。也就是说，要在 100 个处理器上实现 80 的加速，只有 0.25% 的原始计算可以是顺序的。这向我们展示了编写并行程序以利用多个处理器的能力的重要性。在实践中，程序不仅在完全并行或顺序模式下运行，而且在并行模式下运行时通常使用的处理器数量少于全部处理器。

 

第二个挑战是处理器之间的通信成本相对较高。如果我们考虑运行在 1 GHz 的 32 处理器多处理器。并且只有 0.2% 的指令涉及需要 400ns/访问的远程通信引用，即使使用最乐观的计算也可以表明，如果没有远程引用，多处理器将快 2.6 倍。这就是通信开销的影响，必须适当处理。

 

减少通信开销的一种解决方案是利用缓存并缓存每个处理器所需的数据。缓存用于增加带宽并减少访问延迟。它们对于私有数据和共享数据都很有价值。但是，我们必须处理缓存一致性等问题。这将在后续模块中详细说明。

 

总而言之，我们已经研究了对多处理器系统的需求。ILP 和 TLP 的限制以及功率和热量限制使我们从复杂的单处理器转向更简单的多核。有不同风格的并行架构。我们已经讨论了主要类别及其优缺点。还有不同的编程模型可用。最后，我们讨论了与多处理器系统相关的主要挑战。

 

网页链接/支持材料

计算机组织与设计——硬件/软件接口，David A. Patterson 和 John L. Hennessy，第 4 版，Morgan Kaufmann，Elsevier，2009 年。
Computer Architecture – A Quantitative Approach，John L. Hennessy 和 David A.Patterson，第 5 版，Morgan Kaufmann，Elsevier，2011。
```
